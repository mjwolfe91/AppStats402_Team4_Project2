---
title: "StatsProj2WolfeRF"
author: "Michael J Wolfe"
date: "August 2, 2019"
output:
  word_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Packages

```{r}
library(RCurl)
library(dplyr)
library(ggplot2)
library(gplots)
library(randomForest)
library(rgl)
library(tree)
library(ISLR)
library(ROCR)
library(RColorBrewer)
library(pheatmap)
library(MASS)
library(rpart)
library(rpart.plot)
library(ROSE)
```
The city of Framingham is concerned about the long term health of some of its citizens. In this exercise we will test probability models on a variety of factors that lead to coronary heart disease and recommend one solution.

## Load Data

```{r}
heartURL <- getURL("https://raw.githubusercontent.com/mjwolfe91/AppStats402_Team4_Project2/master/data/framingham.csv")
heartData <- read.csv(text=heartURL, header=TRUE)
#heartData <- read.csv('C:/Users/micha/OneDrive/Desktop/SMU MSDS/Applied Stats/Project 2/Data/framingham.csv')
head(heartData)
```

Some of these data have categories that aren't particularly intuitive. Let's recode some of them.

## Rename columns

```{r recode}
#https://dplyr.tidyverse.org/reference/recode.html

heartData$male = dplyr::recode(heartData$male, '1' = 'male', '0' = 'female')
names(heartData)[1] = 'Gender'
unique(heartData$Gender)

heartData$education = recode(heartData$education, '1'='SomeHighSchool', '2'='FinishedHighSchool/GED',
       '3'='SomeCollege/VocationalSchool', '4'='College')
unique(heartData$education)

heartData$currentSmoker = recode(heartData$currentSmoker, '1'='Yes', '0'='No')
unique(heartData$currentSmoker)

heartData$BPMeds = recode(heartData$BPMeds, '1'='Yes', '0'='No')
unique(heartData$BPMeds)

unique(heartData$prevalentStroke)
heartData$prevalentStroke = recode(heartData$prevalentStroke, '1'='Yes', '0'='No')

unique(heartData$prevalentHyp)
heartData$prevalentHyp = recode(heartData$prevalentHyp, '1'='Yes', '0'='No')

unique(heartData$TenYearCHD)
heartData$TenYearCHD = recode(heartData$TenYearCHD, '1'='Yes', '0'='No')

unique(heartData$diabetes)
heartData$diabetes = recode(heartData$diabetes, '1'='Yes', '0'='No')
```

## EDA

## Column analysis and cleanup

Let's first confirm that our datatypes agree with the analysis we want to do.

```{r pairs}
sapply(heartData, class)
```

Those character columns would do better as factors, so let's change them.

```{r pairs2}
cols_factor <- c("Gender", "education", "currentSmoker", "BPMeds", "prevalentStroke", "prevalentHyp", "diabetes", "TenYearCHD")
heartData[cols_factor] <- lapply(heartData[cols_factor], factor)
```

Now let's take some sums and summaries.

```{r}
numeric_cols <- subset(heartData, select = -c(Gender, education, currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, TenYearCHD))
colSums(numeric_cols)
colSums(is.na(heartData))
summary(heartData)
```

Looks like there's some missing values in cigsPerDay, totChol, heartRate, and glucose. Let's see how much leverage these values have.

```{r}
dim(heartData)
dim(na.omit(heartData))
3658/4240
```

We can keep 86% of our values, so let's go ahead and remove these rows.

```{r}
heartData = na.omit(heartData)
dim(heartData)
summary(heartData)
```

Much better! However, it would be easier to interpret the model outcome as a person with _ is _ more likely to be diagnosed with heart disease, so let's adjust the response variable accordingly.

```{r}
levels(heartData$TenYearCHD)
heartData$TenYearCHD = relevel(heartData$TenYearCHD, ref='No')
table(heartData$TenYearCHD)
557/3658
```

After re-factoring the response variable it appears to be an unbalanced binary, with only about 15% of residents developing coronary heart disease after 10 years. This will need to be considered when created confusion matrices and scoring accuracy. We will likely need to create several cross-validation iterations, and possibly downsample if it appears our train/test splits skew too heavily towards "No" and create a falsly inflated accuracy score.

## Continuous variables

Let's start by checking correlations.

```{r glucose}
aggregate(glucose~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=glucose)) + geom_boxplot()
```

Lots of outliers here. Hard to say if there is correlation because of this.

```{r heartrate}
aggregate(heartRate~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=heartRate)) + geom_boxplot()
```

No correlation here.

```{r BMI}
aggregate(BMI~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=BMI)) + geom_boxplot()
```

Looks like high BMI and heart disease might be correlated.

```{r diastolic BP}
aggregate(diaBP~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=diaBP)) + geom_boxplot()
```

Similarly appears that high diastolic BP correlates to ten year CHD.

```{r systolic BP}
aggregate(sysBP~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=sysBP)) + geom_boxplot()
```

Same with systolic BP.

```{r total cholesterol}
aggregate(totChol~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=totChol)) + geom_boxplot()
```

Again with cholesterol.

```{r cigarettes per day}
aggregate(cigsPerDay~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=cigsPerDay)) + geom_boxplot()
```

Yet again with cigarette use. Lots of outliers here too.

```{r age}
aggregate(age~TenYearCHD, data=heartData, summary)
ggplot(heartData, aes(x=TenYearCHD, y=age)) + geom_boxplot()
```

Higher age appears to be associated with CHD as well.

Let's run some histograms.

```{r histograms}
for (i in colnames(numeric_cols)){
  hist(heartData[[i]])
}
```

Mostly normally distributed with a couple exceptions. Now let's check mutlicolinearity and correlations.

```{r pairs correlation}
require(dplyr)
pairs(~ age + cigsPerDay + totChol + sysBP + diaBP + BMI + heartRate + glucose, data=heartData)
pairs(~ age + cigsPerDay + totChol + sysBP + diaBP + BMI + heartRate + glucose, data=heartData,
      col=heartData$TenYearCHD)

heartData.cor <- heartData %>% dplyr::select(age, cigsPerDay, totChol, sysBP, diaBP, BMI, heartRate, glucose) %>%
  cor()
heartData.cor
heatmap.2(heartData.cor,col=redgreen(20), 
          density.info="none", trace="none", dendrogram=c("row"), 
          symm=F,symkey=T,symbreaks=T, scale="none")
```

There's a strong correlation between systolic blood pressure and diastolic blood pressure...which makes practical sense considering they are essentially the same measure. Age does a good job of stratifying the variables and reducing multicollinearity. Two takeaways from this - first might be to remove either systolic or diastolic BP, second is to perhaps create interactions on the age variable.

## Categorical variables

Next let's check the categorical variables, first by measuring and plotting proportionality.

```{r diabetes}
attach(heartData)
prop.table(table(TenYearCHD,diabetes),2)
plot(TenYearCHD~diabetes,col=c("red","blue"))
```

There appears to be an unbalanced response rate. We will need to keep this in mind when creating training data, and will likely necessitate a correction to the coefficient. It also appears that prevalent diabetes is associated with ten year CHD.

```{r prevalentHyp}
prop.table(table(TenYearCHD,prevalentHyp),2)
plot(TenYearCHD~prevalentHyp,col=c("red","blue"))
```

Again we see prevalent hypertension associated with ten year CHD.

```{r prevalentStroke}
prop.table(table(TenYearCHD,prevalentStroke),2)
plot(TenYearCHD~prevalentStroke,col=c("red","blue"))
```

Another association

```{r BPMeds}
prop.table(table(TenYearCHD,BPMeds),2)
plot(TenYearCHD~BPMeds,col=c("red","blue"))
```

Another association, and class imbalance

```{r currentSmoker}
prop.table(table(TenYearCHD,currentSmoker),2)
plot(TenYearCHD~currentSmoker,col=c("red","blue"))
```

Oddly appears that there is no association between smoking and ten year CHD

```{r education}
prop.table(table(TenYearCHD,education),2)
mosaicplot(TenYearCHD~education, las=1, main = 'Education vs Heart Disease')
```

Higher education appears to have lower rates of ten year CHD.

```{r gender}
prop.table(table(TenYearCHD,currentSmoker),2)
plot(TenYearCHD~Gender,col=c("red","blue"), las=1)
```

Males appear to develop CHD more often.

```{r ftables}
ftable(addmargins(table(heartData$TenYearCHD,heartData$currentSmoker))) 
ftable(addmargins(table(heartData$TenYearCHD,heartData$Gender))) 
ftable(addmargins(table(heartData$TenYearCHD,heartData$education))) 
ftable(addmargins(table(heartData$TenYearCHD,heartData$BPMeds))) 
ftable(addmargins(table(heartData$TenYearCHD,heartData$prevalentStroke))) 
ftable(addmargins(table(heartData$TenYearCHD,heartData$prevalentHyp))) 
ftable(addmargins(table(heartData$TenYearCHD,heartData$diabetes)))
```

##PCA

Let's see if we can reduce this dataset down to a few principle components. Let's also remove Systolic BP, since there is a lot of correlation between SysBP and DiaBP.

```{r pca}
require(dplyr)
heartData <- dplyr::select(heartData, -sysBP)
numeric_cols <- subset(heartData, select = -c(Gender, education, currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, TenYearCHD))
pc.result<-prcomp(numeric_cols,scale.=TRUE)
pc.scores<-pc.result$x
pc.scores<-data.frame(pc.scores)
pc.scores$TenYearCDH<-heartData$TenYearCHD
pc.result$rotation
```

Looks like fairly even variance. It's possible using PC's won't make much of a difference. Let's check the Scree plots and clustering.

```{r pca2}
pc.eigen<-(pc.result$sdev)^2
pc.prop<-pc.eigen/sum(pc.eigen)
pc.cumprop<-cumsum(pc.prop)
plot(1:7,pc.prop,type="l",main="Scree Plot",ylim=c(0,1),xlab="PC #",ylab="Proportion of Variation")
lines(1:7,pc.cumprop,lty=3)
```

If we were extremely conservative and used 0.1 as a cutoff we would still likely have 7 components. Looks like our initial assumption that using PC's is not the way to go might have been correct. Let's do some clustering around the first few PC's and confirm.

```{r pca3}
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
  geom_point(aes(col=TenYearCHD), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  ggtitle("PCA plot of Coronary Heart Disease Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC3)) +
    geom_point(aes(col=TenYearCHD), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Coronary Heart Disease Data")

  
ggplot(data = pc.scores, aes(x = PC2, y = PC3)) +
    geom_point(aes(col=TenYearCHD), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Coronary Heart Disease Data")
```

Separation isn't great in any of these. We will not use PCA for this data. Since the continuous As this is a predictive model, it does not make pratical sense

##Random Forest Model

Let's start by splitting our data into training and test data. We will use this split for all future tasks.

```{r training test}
smp_size <- floor(0.75 * nrow(heartData))
set.seed(123)
train_ind <- sample(seq_len(nrow(heartData)), size = smp_size)

heartData.train <- heartData[train_ind, ]
heartData.test <- heartData[-train_ind, ]
heartData.train.under <- ovun.sample(TenYearCHD~., data=heartData.train, method='under',
                                N=(444*2), seed=1)$data
heartData.train.over <- ovun.sample(TenYearCHD~., data=heartData.train, method='over',
                                N=(2482*2), seed=1)$data
```

Let's try some clustering.

```{r randomforest eda}
cols <- colorRampPalette(brewer.pal(9, "Set1"))
x<-t(subset(heartData.train, select = -c(Gender, education, currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, TenYearCHD)))
colnames(x)<-heartData.train$TenYearCHD
pheatmap(x,annotation_col=data.frame(TenYearCHD=heartData.train$TenYearCHD),annotation_colors=list(TenYearCHD=c("0"="white","1"="green")),scale="row",legend=T,color=colorRampPalette(c("blue","white", "red"), space = "rgb")(100))
```

Similar to the earlier heatmap we are seeing a lot of clustering around blood pressure.
Now to create and train the model.

```{r random forest}
heartData.rf<-randomForest(TenYearCHD~., data=heartData.train,mtry=5,importance=T,ntree=100)
fit.pred<-predict(heartData.rf,newdata=heartData.test,type="response")
table(fit.pred,heartData.test$TenYearCHD)
```

Lots of false positives. Let's try an undersampled model.

```{r random forest under}
heartData.rf.under<-randomForest(TenYearCHD~., data=heartData.train.under,mtry=5,importance=T,ntree=100)
fit.pred.under<-predict(heartData.rf.under,newdata=heartData.test,type="response")
table(fit.pred.under,heartData.test$TenYearCHD)
```

Now too many false negatives! Let's try an oversampled model now.

```{r random forest over}
heartData.rf.over<-randomForest(TenYearCHD~., data=heartData.train.over,mtry=5,importance=T,ntree=100)
fit.pred.over<-predict(heartData.rf.over,newdata=heartData.test,type="response")
table(fit.pred.over,heartData.test$TenYearCHD)
```

Not much improvement. Not likely we will get much accuracy out of this model but let's test anyway.

```{r random forest ROC}
rf.pred<-predict(heartData.rf,newdata=heartData.test,type="prob")
pred <- prediction(rf.pred[,2], heartData.test$TenYearCHD)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
plot(roc.perf,main="AUC of CHD Random Forest Test")
abline(a=0, b= 1)
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
plot(heartData.rf, type ="l",main=deparse(substitute(heartData.rf)))
```

As expected, not a great accuracy score, but perhaps we can get some insight from the variable importance analysis.

```{r random forest variable importance}
varImpPlot (heartData.rf,type=1,main="Variable Importance")
varImpPlot (heartData.rf,type=2,main="Variable Importance")

attach(heartData)
plot3d(sysBP,totChol,age,col=ifelse(TenYearCHD=="Yes","red","black"),size=4)

#index1<-which(Indexwhich=="Yes")
#plot3d(sysBP[index1],totChol[index1],age[index1],col=ifelse(TenYearCHD=="Yes","red","black")[index1],size=4)

#index2<-which(Indexwhich=="Medium")
#plot3d(sysBP[index2],totChol[index2],age[index2],col=ifelse(TenYearCHD=="Yes","red","black")[index2],size=4)

#index3<-which(Indexwhich=="GoIndexwhichod")
#plot3d(sysBP[index3],totChol[index3],age[index3],col=ifelse(TenYearCHD=="Yes","red","black")[index3],size=4)
```

This affirms what we saw in model selection: blood pressure/hypertension, age, gender, and cigarette usage have the greatest impact on development of coronary heart disease.

##QDA

Given that several of the continuous variables were critical for model accuracy according to the EDA, let's try some discriminant analysis. Since we same some non-normal distributions (lots of 0's in cigarette usage), let's use QDA so we can remain robust to violations in assumptions.

```{r QDA}
heartData.train.x <- subset(heartData.train, select = -c(Gender, education, currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, TenYearCHD))
heartData.train.y <- heartData.train$TenYearCHD
fit.qda <- qda(heartData.train.y ~ ., data = heartData.train.x)
pred.qda <- predict(fit.qda, newdata = heartData.train.x)
table(pred.qda$class, heartData.train.y)
```

Again it appears we are going to need to undersampled to account for the unbiased response

```{r QDA Under}
heartData.train.under.x <- subset(heartData.train.under, select = -c(Gender, education, currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, TenYearCHD))
heartData.train.under.y <- heartData.train.under$TenYearCHD
fit.qda.under <- qda(heartData.train.under.y ~ ., data = heartData.train.under.x)
pred.qda.under <- predict(fit.qda.under, newdata = heartData.train.under.x)
table(pred.qda.under$class, heartData.train.under.y)
```

Still not very accurate but some improvement. Let's try a test fit and see how accurate it is.

```{r QDA 2}
preds <- pred.qda.under$posterior
preds <- as.data.frame(preds)

pred <- prediction(preds[,2],heartData.train.under.y)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
plot(roc.perf)
abline(a=0, b= 1)
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
table(pred.qda.under$class, heartData.train.under.y)
```

Pretty good results for a basic QDA model. Most of the inaccuracy seems to come from false positives.

```{r LDA reduced}
#heartData.train <- heartData[1:3000,]
#heartData.train.x <- heartData.train[,1:15]
#reduced.lda <- lda(heartData.train.y ~ age+diaBP+cigsPerDay+diabetes+prevalentStroke, data = heartData.train.x)
#pred.lda <- predict(reduced.lda, newdata = heartData.train)

#preds <- pred.lda$posterior
#preds <- as.data.frame(preds)

#pred <- prediction(preds[,2],dat.train.y)
#roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
#auc.train <- performance(pred, measure = "auc")
#auc.train <- auc.train@y.values
#plot(roc.perf)
#abline(a=0, b= 1)
#text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))

```

Great ROC score, and the confusion matrix looks balanced.

```{r decision tree}
par(mfrow=c(1,1))
tree.deep<-tree(TenYearCHD~., data=heartData) #default is for atleast 5 observations in the child nodes for split to occur
summary(tree.deep)
plot(tree.deep)
text(tree.deep,pretty=0)
```

```{r cv pruning}
set.seed(123)
cv.chd=cv.tree(tree.deep,FUN=prune.tree,method="deviance")
names(cv.chd)
cv.chd
plot(cv.chd)
par(mfrow=c(1,1))
plot(cv.chd$size,cv.chd$dev,type="b")
prune.chd=prune.tree(tree.deep,best=8)
plot(prune.chd)
text(prune.chd,pretty=0)
```


```{r decision tree2, eval=FALSE}
### Decision Tree

term_vars <- c("Gender","age", "education","currentSmoker", "cigsPerDay", "BPMeds", "prevalentStroke", "prevalentHyp", "diabetes", "totChol",	"diaBP", 	"BMI", "heartRate", "glucose", "TenYearCHD")
#term_vars <- c("male","age", "currentSmoker", "prevalentStroke", "prevalentHyp", "diabetes", 	"sysBP",	"diaBP", "education",	"cigsPerDay", "BPMeds", "totChol", "BMI", "heartRate", "glucose", "TenYearCHD")
CHD_term_train <- heartData[1:3000,]
CHD_term_test <- heartData[3001:nrow(heartData),]
set.seed(99)  # set a pre-defined value for the random seed so that results are repeatable
# Decision tree model
rpart_model <- rpart(TenYearCHD ~.,
                     data = CHD_term_train[term_vars],
                     method = 'class',
                     parms = list(split='information'),
                     control = rpart.control(usesurrogate = 0,
                                             maxsurrogate = 0))
# Plot the decision tree
rpart.plot(rpart_model, roundint = FALSE, type = 3)

```






