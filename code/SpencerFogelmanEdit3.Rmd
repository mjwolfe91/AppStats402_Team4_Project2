---
title: "Untitled"
author: "Spencer Fogelman"
date: "7/28/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
df = read.csv('/Users/spencerfogelman/Desktop/LogisticRegressionProject/AppStats402_Team4_Project2/data/framingham.csv', header = TRUE)
head(df)
```

#Rename columns

```{r recode}
#https://dplyr.tidyverse.org/reference/recode.html
library(dplyr)
df$male = dplyr::recode(df$male, '1' = 'male', '0' = 'female')
names(df)[1] = 'Gender'
unique(df$Gender)
```

```{r}
df$education = dplyr::recode(df$education, '1'='SomeHighSchool', '2'='FinishedHighSchool/GED',
       '3'='SomeCollege/VocationalSchool', '4'='College')
unique(df$education)
```

```{r}
df$currentSmoker = dplyr::recode(df$currentSmoker, '1'='Yes', '0'='No')
unique(df$currentSmoker)
```
```{r}
df$BPMeds = dplyr::recode(df$BPMeds, '1'='Yes', '0'='No')
unique(df$BPMeds)
```
```{r}
unique(df$prevalentStroke)
df$prevalentStroke = dplyr::recode(df$prevalentStroke, '1'='Yes', '0'='No')
```
```{r}
unique(df$prevalentHyp)
df$prevalentHyp = dplyr::recode(df$prevalentHyp, '1'='Yes', '0'='No')
```
```{r}
unique(df$TenYearCHD)
df$TenYearCHD = dplyr::recode(df$TenYearCHD, '1'='Yes', '0'='No')
```
```{r}
unique(df$diabetes)
df$diabetes = dplyr::recode(df$diabetes, '1'='Yes', '0'='No')
```

#Missingness 
```{r}
summary(df)
#Missing values in cigsPerDay, totChol, heartRate, glucose
```

```{r}
dim(df)
dim(na.omit(df))
3658/4240
#kept 86 percent of data by dropping incomplete observations. I will drop the oberservations
```

```{r}
#before dropping the data
library(ggplot2)
ggplot(df, aes(x=TenYearCHD)) + geom_bar() +
geom_text(stat='count', aes(label=..count..), vjust=2, color='white')
```

```{r}
index_na = apply(is.na(df), 1, sum)>0
null_df = df[index_na,]
head(null_df)
```

```{r}
ggplot(null_df, aes(x=TenYearCHD)) + geom_bar() +
geom_text(stat='count', aes(label=..count..), vjust=2, color='white')
#nulls dont seem to favor yes or no
```

```{r}
#drop the rows
df = na.omit(df)
dim(df)
```

#Changing data types
```{r}
df$Gender = as.factor(df$Gender)
df$education = as.factor(df$education)
df$currentSmoker = as.factor(df$currentSmoker)
df$BPMeds = as.factor(df$BPMeds)
df$prevalentStroke = as.factor(df$BPMeds)
df$prevalentHyp = as.factor(df$prevalentHyp)
df$diabetes = as.factor(df$diabetes)
df$TenYearCHD = as.factor(df$TenYearCHD)
```

```{r}
summary(df)
#df is now clean
```

```{r}
levels(df$TenYearCHD)
df$TenYearCHD = relevel(df$TenYearCHD, ref='No')
#Now our interpretations will be a person with _ is _ more likely to be diagnosed with heart disease.
```

#summary stats for continuous variables
```{r glucose}
aggregate(glucose~TenYearCHD, data=df, summary)
library(ggplot2)
ggplot(df, aes(x=TenYearCHD, y=glucose)) + geom_boxplot()
# hard to tell with this many outliers. does not seem like there is a correlation
```

```{r heartrate}
aggregate(heartRate~TenYearCHD, data=df, summary)
ggplot(df, aes(x=TenYearCHD, y=heartRate)) + geom_boxplot()
#does not seem like there is a correlation
```

```{r BMI}
aggregate(BMI~TenYearCHD, data=df, summary)
ggplot(df, aes(x=TenYearCHD, y=BMI)) + geom_boxplot()
#seems like high BMI is associated with heart disease
```

```{r diastolic BP}
aggregate(diaBP~TenYearCHD, data=df, summary)
ggplot(df, aes(x=TenYearCHD, y=diaBP)) + geom_boxplot()
#higher diastolic bp seems to be related to heart disease
```

```{r systolic BP}
aggregate(sysBP~TenYearCHD, data=df, summary)
ggplot(df, aes(x=TenYearCHD, y=sysBP)) + geom_boxplot()
#higher systolic bp seems to be associated with heart disease
```

```{r total cholesterol}
aggregate(totChol~TenYearCHD, data=df, summary)
ggplot(df, aes(x=TenYearCHD, y=totChol)) + geom_boxplot()
#higher total cholesterol seems to associated with heart disease
```

```{r cigarettes per day}
aggregate(cigsPerDay~TenYearCHD, data=df, summary)
ggplot(df, aes(x=TenYearCHD, y=cigsPerDay)) + geom_boxplot()
#higher cigs per day seems to be associated with heart disease
#what to do with outliers?
```

```{r age}
aggregate(age~TenYearCHD, data=df, summary)
ggplot(df, aes(x=TenYearCHD, y=age)) + geom_boxplot()
#higher age seems to be associated with heart disease
```
#Multicollinearity
```{r}
attach(df)
pairs(~ age + cigsPerDay + totChol + sysBP + diaBP + BMI + heartRate + glucose, data=df)
#seems to be strong linear correlation between systolic BP and diastolic BP, and
#weaker correlation between both and BMI
```

```{r}
pairs(~ age + cigsPerDay + totChol + sysBP + diaBP + BMI + heartRate + glucose, data=df,
      col=TenYearCHD)
#seems like age does a really good job at separation
```

```{r}
df %>% select(age, cigsPerDay, totChol, sysBP, diaBP, BMI, heartRate, glucose) %>%
  cor()
#probably would remove either sysBP or diaBP
```


#EDA for categorical variables

```{r diabetes}
prop.table(table(TenYearCHD,diabetes),2)
plot(TenYearCHD~diabetes,col=c("red","blue"))
#seems to be association between having diabetes and heart disease
#class imbalance
```

```{r prevalentHyp}
prop.table(table(TenYearCHD,prevalentHyp),2)
plot(TenYearCHD~prevalentHyp,col=c("red","blue"))
#prevalent hypertension associated with heart disease
```

```{r prevalentStroke}
prop.table(table(TenYearCHD,prevalentStroke),2)
plot(TenYearCHD~prevalentStroke,col=c("red","blue"))
#stroke associated with heart disease
#class imbalance
```

```{r BPMeds}
prop.table(table(TenYearCHD,BPMeds),2)
plot(TenYearCHD~BPMeds,col=c("red","blue"))
#BP meds associated with heart disease
#class imbalance
```

```{r currentSmoker}
prop.table(table(TenYearCHD,currentSmoker),2)
plot(TenYearCHD~currentSmoker,col=c("red","blue"))
#does not seem to be associated with heart disease which is strange
```

```{r education}
prop.table(table(TenYearCHD,education),2)
mosaicplot(TenYearCHD~education, las=1, main = 'Education vs Heart Disease')
#seems like as education increases, heart disease decreases
```

```{r gender}
prop.table(table(TenYearCHD,currentSmoker),2)
plot(TenYearCHD~Gender,col=c("red","blue"), las=1)
#males seem more likely to get heart disease
```

#Fitting Logistic Regression Model
#Drop sysBA

```{r}
df_model = dplyr::select(df, -sysBP)
names(df_model)
```

```{r}
model.full = glm(TenYearCHD ~ Gender + age + education + currentSmoker + cigsPerDay +
                   BPMeds + prevalentHyp + prevalentStroke + diabetes +
                   totChol + diaBP + BMI + heartRate + glucose , data=df_model,
                 family = binomial(link="logit"))

```

```{r}
library(car)
(vif(model.full)[,3])^2
```
```{r}
alias(model.full)
```

```{r}
plot(prevalentStroke~BPMeds, col=c('red', 'blue'))
table(prevalentStroke, BPMeds)
#all people who have strokes on BPmeds
```

```{r}
#remove prevalent stroke
df_model = dplyr::select(df_model, -prevalentStroke)
model.full = glm(TenYearCHD ~ Gender + age + education + currentSmoker + cigsPerDay +
                   BPMeds + prevalentHyp + diabetes +
                   totChol + diaBP + BMI + heartRate + glucose , data=df_model,
                 family = binomial(link="logit"))
vif(model.full)[,3]^2
#vifs seem good
```

## Train Test Split and Forward Selection

```{r Train Test Split without downsampling}
## 80% of the sample size
smp_size = floor(0.80 * nrow(df_model))

## set the seed to make your partition reproducible
set.seed(123)
train_ind = sample(seq_len(nrow(df_model)), size = smp_size)

#80/20 train test split
train_forward = df_model[train_ind, ]
test_forward = df_model[-train_ind, ]
```


```{r forward selection}
model.full = glm(TenYearCHD ~ Gender + age + education + currentSmoker + cigsPerDay +
                   BPMeds + prevalentHyp + diabetes +
                   totChol + diaBP + BMI + heartRate + glucose , data=train_forward,
                 family = binomial(link="logit"))

model.null<-glm(TenYearCHD ~ 1, data=train_forward,family = binomial(link="logit"))

step(model.null,
     scope = list(upper=model.full),
     direction="forward",
     test="Chisq",
     data=train_forward)
```

Final model from forward selection includes age, hypertension, gender, glucose, cigsperday, diabp

```{r}
#odds ratios
model_1_forward = glm(TenYearCHD~age+prevalentHyp+cigsPerDay+glucose+Gender+diaBP,
              data=train_forward, family = binomial(link="logit"))
exp(cbind("Odds ratio" = coef(model_1_forward), confint.default(model_1_forward, level = 0.95)))
#interpreations all make sense
```

```{r}
#everything statistically significant
summary(model_1_forward)
```

```{r}
plot(model_1_forward)
#no outliers
```

#Interpretations from forward regression

#Accuracy from forward regression and roc curve
```{r}
library(pROC)
predictions_forward = predict(model_1_forward, newdata = test_forward)
observed_forward = test_forward$TenYearCHD
pROC_obj = roc(observed_forward,predictions_forward,smoothed=FALSE,ci=FALSE,plot=TRUE,print.auc=TRUE)

```

```{r}
predictions_classes_forward = ifelse(predictions_forward > 0.05, "Yes", "No")
table(predictions_classes_forward, observed_forward)
#really low power
```

```{r}
mean(predictions_classes_forward == observed_forward)
```

#Undersampling
```{r class imbalance}
table(train_forward$TenYearCHD)
prop.table(table(train_forward$TenYearCHD))
```

```{r train test split downsampling}
library(ROSE)
train_undersample = ovun.sample(TenYearCHD~., data=train_forward, method='under',
                                N=(444*2), seed=1)$data
table(train_undersample$TenYearCHD)
```

```{r}
model.full.undersample = glm(TenYearCHD ~ Gender + age + education + currentSmoker + cigsPerDay +
                   BPMeds + prevalentHyp + diabetes +
                   totChol + diaBP + BMI + heartRate + glucose , data=train_undersample,
                 family = binomial(link="logit"))

model.null.undersample<-glm(TenYearCHD ~ 1, data=train_undersample,family = binomial(link="logit"))

step(model.null.undersample,
     scope = list(upper=model.full.undersample),
     direction="forward",
     test="Chisq",
     data=train_undersample)
```

```{r}
model.forward.undersample = glm(TenYearCHD~age+prevalentHyp+cigsPerDay+glucose+Gender+diaBP,
              data=train_undersample, family = binomial(link="logit"))
```

```{r}
predictions.forward.undersample = predict(model.forward.undersample, newdata = test_forward)
observed_forward = test_forward$TenYearCHD
pROC_obj = roc(observed_forward,predictions.forward.undersample,smoothed=FALSE,ci=FALSE,plot=TRUE,print.auc=TRUE)
```

```{r}
predictions.classes.undersample= ifelse(predictions.forward.undersample > 0.05, "Yes", "No")
table(predictions.classes.undersample, observed_forward)
```

```{r}
#Accuracy went down
mean(predictions.classes.undersample == observed_forward)
```

#Oversampling
```{r}
train_oversample = ovun.sample(TenYearCHD~., data=train_forward, method='over',
                                N=(2482*2), seed=1)$data
table(train_oversample$TenYearCHD)
```

```{r}
model.full.oversample = glm(TenYearCHD ~ Gender + age + education + currentSmoker + cigsPerDay +
                   BPMeds + prevalentHyp + diabetes +
                   totChol + diaBP + BMI + heartRate + glucose , data=train_oversample,
                 family = binomial(link="logit"))

model.null.oversample<-glm(TenYearCHD ~ 1, data=train_oversample,family = binomial(link="logit"))

step(model.null.oversample,
     scope = list(upper=model.full.oversample),
     direction="forward",
     test="Chisq",
     data=train_oversample)
```

```{r}
model.forward.oversample = glm(TenYearCHD~prevalentHyp + glucose + diaBP+
                                 education + currentSmoker + BPMeds + age +
                                 Gender + cigsPerDay + totChol,
              data=train_oversample, family = binomial(link="logit"))

predictions.forward.oversample = predict(model.forward.oversample, newdata = test_forward)
observed_forward = test_forward$TenYearCHD
pROC_obj = roc(observed_forward,predictions.forward.oversample,smoothed=FALSE,ci=FALSE,plot=TRUE,print.auc=TRUE)

```

```{r}
predictions.classes.oversample= ifelse(predictions.forward.oversample > 0.05, "Yes", "No")
table(predictions.classes.oversample, observed_forward)
```

```{r}
mean(predictions.classes.oversample == observed_forward)
```

#Train Test Split and Lasso Regression
```{r train test split}
#80/20 train test split
train = train_forward
test = test_forward
```


```{r ridge regression preparation}
#converts categorical variables to dummy variables predictor matrix 
#removes redundant columns (Ex: only keep either 'Yes' or 'No' column)
#[,-1] removes extra information at end
x = model.matrix(TenYearCHD ~ ., data = train_undersample)[, -1]
# creates our response variable as numerical variables
y = ifelse(train_undersample$TenYearCHD == 'Yes', 1, 0)
```


```{r ridge regression}
library(glmnet)
#Find best lambda parameter using cross validation
set.seed(123)
#alpha=1 specifies lasso regression
cv.lasso = cv.glmnet(x, y, alpha = 1, family = "binomial")
```

```{r lambda plots}
plot(cv.lasso)
```

```{r lambda values}
cv.lasso$lambda.min
```

```{r}
# Fit the final model on the training data
model_lasso <- glmnet(x, y, alpha = 1, family = "binomial",
                lambda = cv.lasso$lambda.min)
```

```{r}
# Display regression coefficients
coef(model_lasso)
```

```{r odds ratios}
coefficients_lasso = coef(model_lasso)[, 's0']
coefficients_lasso = round(x = coefficients_lasso, digits=3)
coefficients_lasso = coefficients_lasso[coefficients_lasso != 0.000]
coefficients_lasso
```

```{r odds ratios}
odds_ratios_lasso = exp(coefficients_lasso)
odds_ratios_lasso
```


```{r predicitons on test data}
# Make predictions on the test data
x.test_lasso = model.matrix(TenYearCHD ~., data= test)[,-1]
probabilities_lasso = predict(object = model_lasso, newx=x.test_lasso)
predicted.classes_lasso = ifelse(probabilities_lasso > 0.5, "Yes", "No")
```


```{r}
# Model accuracy: 77%
observed.classes_lasso = test$TenYearCHD
mean(predicted.classes_lasso == observed.classes_lasso)
```

```{r}
table(observed.classes_lasso, predicted.classes_lasso)
#lots of false negatives
```

```{r roc curve}
library(pROC)
pROC_obj = roc(observed.classes_lasso,probabilities_lasso[,1],smoothed=FALSE,ci=FALSE,plot=TRUE,print.auc=TRUE)
#slightly better than the forward selection model based on ROC, but slightly worse based on accuracy
```

#Model with Interactions

```{r}
x_complex = model.matrix(TenYearCHD~.+Gender:age+ Gender:education+Gender:currentSmoker+
                        Gender:cigsPerDay+Gender:BPMeds+
                        Gender:prevalentHyp + Gender:diabetes + Gender:totChol+
                        Gender:diaBP+ Gender:BMI + Gender:heartRate +
                        Gender:glucose, data=train_undersample)[, -1]
cv.lasso_complex = cv.glmnet(x_prac, y, alpha = 1, family = "binomial")
model_lasso_complex = glmnet(x_prac, y, alpha = 1, family = "binomial",
                lambda = cv.lasso_prac$lambda.min)
coef(model_lasso_complex)
```

```{r}
x.test_complex = model.matrix(TenYearCHD~.+Gender:age+ Gender:education+Gender:currentSmoker+
                        Gender:cigsPerDay+Gender:BPMeds+
                        Gender:prevalentHyp + Gender:diabetes + Gender:totChol+
                        Gender:diaBP+ Gender:BMI + Gender:heartRate +
                        Gender:glucose, data= test)[,-1]
probabilities_complex = predict(object = model_lasso_complex, newx=x.test_complex)
predicted.classes_complex = ifelse(probabilities_complex > 0.5, "Yes", "No")
```

```{r}
#Predictions did not change
table(predicted =predicted.classes_complex, observed = test$TenYearCHD)
mean(predicted.classes_complex == test$TenYearCHD)
```


#LDA
#Assumptions: 
1) Equal Variance-Covariance matrices
#color pairs plot and look at deviation
2) Normality Assumption
#look at qqplots, can drop variables

```{r Assumption 1}
df_lda = select_if(df_model, is.numeric)
head(df_lda)
```

```{r}
df_lda = cbind(df_lda, df_model$TenYearCHD)
head(df_lda)
```

```{r}
names(df_lda)[8] = 'TenYearCHD'
names(df_lda)
```

```{r}
#Check for covariance matrix assumption
pairs(df_lda[,-8], col=df_lda$TenYearCHD)
```


```{r boxM test}
#does not have equal variance-covariance matrix: need to use qda
heplots::boxM(df_lda[, -8], df_lda$TenYearCHD)
```

For normality, check that the variables are normally distributed within the heart disease group and the non heart disease group
```{r Normality Test}
heart_disease =df_lda[df_lda$TenYearCHD == 'Yes',]
no_heart_disease = df_lda[df_lda$TenYearCHD != 'Yes',]
```

```{r check for normality}
for (i in names(df_lda)[-8]){
  hist(heart_disease[,i])
  title(sub = i)
}
#remove glucose, cigsPerDay
```

```{r}
for (i in names(df_lda)[-8]){
  hist(no_heart_disease[,i])
  title(sub = i)
}
```

#QDA
```{r lda}
library(MASS)
qda.model = qda(TenYearCHD~age+totChol+diaBP +BMI+heartRate, data=df_lda)
qda.model
```

```{r qda accuracy}
predictions_qda = predict(qda.model, newdata = test)$class
observed_lda = test$TenYearCHD
table(predictions_qda, observed_lda)
```

```{r}
#accuracy is similar to both lasso and forward selection. Lots of false negatives. 
mean(predictions_qda == observed_lda)
```


#Single Decision Tree
```{r}
index = sample(1:nrow(df), floor(0.8*nrow(df)), replace=FALSE)
train_tree = df[index,]
test_tree = df[-index,]
dim(train_tree)
dim(test_tree)
```

```{r}
model_tree = tree(TenYearCHD~., data = train_tree)
plot(model_tree)
text(model_tree, pretty=0)
```

```{r}
tree.pred = predict(model_tree, test_tree, type='class')
observed_tree = test_tree$TenYearCHD
table(pred_tree, observed_tree)
```

```{r}
set.seed(3)
par(mfrow=c(1,1))
cv_heart_tree = cv.tree(model_tree, FUN=prune.misclass)
plot(cv_heart_tree)
```

#Random Forest
```{r}
randforest = randomForest(TenYearCHD~., data=train_tree, mtry=5, importance=TRUE, ntree=100)
forest_pred = predict(randforest, newdata=test_tree, type='response')
table(forest_pred, test_tree$TenYearCHD)
```



